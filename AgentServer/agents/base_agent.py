from typing import List, Dict, Any, Optional
import json

class BaseAgent:
    """
    åŸºç¡€æ™ºèƒ½ä½“ç±»ï¼Œå°è£…ä¸ LLM çš„äº¤äº’å’Œ ReAct (Reasoning and Acting) å¾ªç¯ã€‚
    """
    def __init__(self, name: str, role_description: str, llm_client, mcp_session=None, model_name: str = "gpt-4o"):
        self.name = name
        self.role_description = role_description
        self.llm_client = llm_client
        self.mcp_session = mcp_session
        self.model_name = model_name
        
        # ç»´æŠ¤æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡è®°å¿†
        self.memory: List[Dict[str, Any]] = [
            {"role": "system", "content": self.role_description}
        ]
        
    def add_message(self, role: str, content: str):
        self.memory.append({"role": role, "content": content})

    async def _execute_tool(self, tool_call) -> str:
        """æ‰§è¡Œ MCP å·¥å…·å¹¶è¿”å›ç»“æœ"""
        function_name = tool_call.function.name
        try:
            function_args = json.loads(tool_call.function.arguments)
        except json.JSONDecodeError:
            return f"Error: Invalid JSON arguments for {function_name}"
            
        print(f"[{self.name}] ğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…· -> {function_name}({function_args})")
        
        if not self.mcp_session:
            return f"Error: MCP session is not initialized for {self.name}"

        try:
            result = await self.mcp_session.call_tool(function_name, arguments=function_args)
            raw_text = result.content[0].text
            print(f"[{self.name}] ğŸ“¦ å·¥å…·è¿”å›ç»“æœ -> {raw_text[:200]}...") # æ‰“å°å‰200å­—ç¬¦
            return raw_text
        except Exception as e:
            error_msg = f"Error executing {function_name}: {str(e)}"
            print(f"[{self.name}] âŒ å·¥å…·æ‰§è¡Œå‡ºé”™ -> {error_msg}")
            return error_msg

    async def run(self, max_turns: int = 5, tools: Optional[List[Dict]] = None) -> str:
        """
        è¿è¡Œ ReAct å¾ªç¯ï¼Œç›´åˆ°å¾—åˆ°æœ€ç»ˆç»“è®ºæˆ–è¾¾åˆ°æœ€å¤§è½®æ•°ã€‚
        """
        turn = 0
        while turn < max_turns:
            print(f"\n--- [{self.name}] æ€è€ƒè½®æ¬¡ {turn + 1}/{max_turns} ---")
            
            # 1. è¯¢é—®å¤§æ¨¡å‹ (æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¸¦å·¥å…·)
            response = await self.llm_client.chat.completions.create(
                model=self.model_name,
                messages=self.memory,
                tools=tools,
                tool_choice="auto" if tools else "none"
            )
            
            response_message = response.choices[0].message
            # å°†å¤§æ¨¡å‹çš„å›å¤åŠ å…¥ä¸Šä¸‹æ–‡
            self.memory.append(response_message)
            
            # 2. åˆ¤æ–­å¤§æ¨¡å‹æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if response_message.tool_calls:
                print(f"[{self.name}] ğŸ§  å†³å®šæ‰§è¡Œ Action...")
                for tool_call in response_message.tool_calls:
                    # æ‰§è¡Œå·¥å…·
                    tool_result = await self._execute_tool(tool_call)
                    
                    # å°†å·¥å…·çš„åé¦ˆç»“æœå°è£…ä¸º tool æ¶ˆæ¯åŠ å…¥ä¸Šä¸‹æ–‡
                    self.memory.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": tool_call.function.name,
                        "content": tool_result
                    })
                # å¾ªç¯ç»§ç»­ï¼Œå¸¦ç€å·¥å…·çš„ç»“æœå†å»é—®å¤§æ¨¡å‹
                turn += 1
                continue
                
            else:
                # 3. å¤§æ¨¡å‹è¾“å‡ºäº†è‡ªç„¶è¯­è¨€çš„ç»“æœï¼ŒReAct å¾ªç¯ç»“æŸ
                print(f"[{self.name}] ğŸ¯ æ€è€ƒå®Œæ¯•ï¼Œå¾—å‡ºæœ€ç»ˆç»“è®ºã€‚")
                return response_message.content
                
        # è¾¾åˆ°æœ€å¤§è½®æ¬¡å¼ºåˆ¶é€€å‡º
        final_msg = f"[{self.name}] âš ï¸ è¾¾åˆ°æœ€å¤§æ€è€ƒè½®æ¬¡ ({max_turns})ï¼Œå¼ºåˆ¶ç»ˆæ­¢æ¨æ¼”ã€‚"
        print(final_msg)
        self.add_message("assistant", final_msg)
        return final_msg
