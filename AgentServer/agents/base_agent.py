from typing import List, Dict, Any, Optional
import json

class BaseAgent:
    """
    åŸºç¡€æ™ºèƒ½ä½“ç±»ï¼Œå°è£…ä¸ LLM çš„äº¤äº’å’Œ ReAct (Reasoning and Acting) å¾ªç¯ã€‚
    åŒ…å«é”™è¯¯å»é‡æœºåˆ¶ï¼šå½“åŒä¸€å·¥å…·è¿ç»­è¿”å›ç›¸åŒé”™è¯¯æ—¶ï¼Œè‡ªåŠ¨æ³¨å…¥æç¤ºå¼•å¯¼å¤§æ¨¡å‹æ¢ç­–ç•¥ã€‚
    """
    def __init__(self, name: str, role_description: str, llm_client, mcp_session=None, model_name: str = "gpt-4o"):
        self.name = name
        self.role_description = role_description
        self.llm_client = llm_client
        self.mcp_session = mcp_session
        self.model_name = model_name
        
        # ç»´æŠ¤æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡è®°å¿†
        self.memory: List[Dict[str, Any]] = [
            {"role": "system", "content": self.role_description}
        ]
        
    def add_message(self, role: str, content: str):
        self.memory.append({"role": role, "content": content})

    async def _execute_tool(self, tool_call) -> str:
        """æ‰§è¡Œ MCP å·¥å…·å¹¶è¿”å›ç»“æœ"""
        function_name = tool_call.function.name
        try:
            function_args = json.loads(tool_call.function.arguments)
        except json.JSONDecodeError:
            return f"Error: Invalid JSON arguments for {function_name}"
            
        print(f"[{self.name}] ğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…· -> {function_name}({function_args})")
        
        if not self.mcp_session:
            return f"Error: MCP session is not initialized for {self.name}"

        try:
            result = await self.mcp_session.call_tool(function_name, arguments=function_args)
            raw_text = result.content[0].text
            print(f"[{self.name}] ğŸ“¦ å·¥å…·è¿”å›ç»“æœ -> {raw_text[:200]}...")  # æ‰“å°å‰200å­—ç¬¦
            return raw_text
        except Exception as e:
            error_msg = f"Error executing {function_name}: {str(e)}"
            print(f"[{self.name}] âŒ å·¥å…·æ‰§è¡Œå‡ºé”™ -> {error_msg}")
            return error_msg

    async def run(self, max_turns: int = 5, tools: Optional[List[Dict]] = None) -> str:
        """
        è¿è¡Œ ReAct å¾ªç¯ï¼Œç›´åˆ°å¾—åˆ°æœ€ç»ˆç»“è®ºæˆ–è¾¾åˆ°æœ€å¤§è½®æ•°ã€‚
        å†…ç½®é”™è¯¯å»é‡æœºåˆ¶ï¼šè¿ç»­ 2 æ¬¡å¯¹åŒä¸€å·¥å…·è·å¾—ç›¸åŒé”™è¯¯ç»“æœæ—¶ï¼Œ
        è‡ªåŠ¨æ³¨å…¥ system æç¤ºï¼Œå¼•å¯¼å¤§æ¨¡å‹è·³è¿‡è¯¥å·¥å…·ç›´æ¥æ¨ç†ã€‚
        """
        turn = 0
        # é”™è¯¯å»é‡è¿½è¸ªå™¨: {tool_name: {"last_error": str, "count": int}}
        error_tracker: Dict[str, Dict[str, Any]] = {}
        MAX_SAME_ERROR = 2  # åŒä¸€å·¥å…·å…è®¸çš„æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°

        while turn < max_turns:
            print(f"\n--- [{self.name}] æ€è€ƒè½®æ¬¡ {turn + 1}/{max_turns} ---")
            
            # 1. è¯¢é—®å¤§æ¨¡å‹ (æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¸¦å·¥å…·)
            kwargs = {
                "model": self.model_name,
                "messages": self.memory
            }
            if tools:
                kwargs["tools"] = tools
                kwargs["tool_choice"] = "auto"
                
            response = await self.llm_client.chat.completions.create(**kwargs)
            
            response_message = response.choices[0].message
            # å°†å¤§æ¨¡å‹çš„å›å¤åŠ å…¥ä¸Šä¸‹æ–‡
            self.memory.append(response_message)
            
            # 2. åˆ¤æ–­å¤§æ¨¡å‹æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            tool_calls = response_message.tool_calls

            # å…¼å®¹ï¼šéƒ¨åˆ†æœ¬åœ°å¤§æ¨¡å‹å¶å°”ä¼šæŠŠå·¥å…· JSON æ¼åœ¨ content é‡Œé¢ï¼Œå¯¼è‡´æœªè½å…¥ tool_calls
            if not tool_calls and response_message.content:
                content_str = response_message.content.strip()
                if '{"name":' in content_str and '"arguments":' in content_str:
                    try:
                        start_idx = content_str.find("{")
                        end_idx = content_str.rfind("}") + 1
                        parsed = json.loads(content_str[start_idx:end_idx])
                        if "name" in parsed and "arguments" in parsed:
                            class DummyFunction:
                                def __init__(self, name, args):
                                    self.name = name
                                    self.arguments = json.dumps(args) if isinstance(args, dict) else args
                            class DummyToolCall:
                                def __init__(self, tid, func):
                                    self.id = tid
                                    self.function = func
                            
                            # åŒ…è£…æˆä¸ OpenAI è¿”å›ä¸€è‡´çš„ç»“æ„
                            tool_calls = [DummyToolCall(f"call_{turn}", DummyFunction(parsed["name"], parsed["arguments"]))]
                            print(f"[{self.name}] ğŸ©¹ è§¦å‘å…¼å®¹å±‚ï¼šä»æ™®é€šæ–‡æœ¬æå–åˆ°éšè—çš„å·¥å…·è°ƒç”¨ -> {parsed['name']}")
                    except Exception:
                        pass

            if tool_calls:
                print(f"[{self.name}] ğŸ§  å†³å®šæ‰§è¡Œ Action...")
                has_blocked_tool = False

                for tool_call in tool_calls:
                    tool_name = tool_call.function.name

                    # æ£€æŸ¥è¯¥å·¥å…·æ˜¯å¦å·²ç»è¿ç»­å¤±è´¥è¿‡å¤šæ¬¡
                    if tool_name in error_tracker and error_tracker[tool_name]["count"] >= MAX_SAME_ERROR:
                        blocked_msg = (
                            f"âš ï¸ å·¥å…· '{tool_name}' å·²è¿ç»­ {error_tracker[tool_name]['count']} æ¬¡è¿”å›ç›¸åŒé”™è¯¯ï¼Œ"
                            f"è·³è¿‡æœ¬æ¬¡è°ƒç”¨ã€‚è¯·æ ¹æ®å·²æœ‰ä¿¡æ¯ç›´æ¥è¿›è¡Œåˆ†ææ¨ç†ï¼Œä¸è¦å†é‡å¤è°ƒç”¨è¯¥å·¥å…·ã€‚"
                        )
                        print(f"[{self.name}] ğŸš« {blocked_msg}")
                        self.memory.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "name": tool_name,
                            "content": blocked_msg
                        })
                        has_blocked_tool = True
                        continue

                    # æ­£å¸¸æ‰§è¡Œå·¥å…·
                    tool_result = await self._execute_tool(tool_call)
                    
                    # å°†å·¥å…·çš„åé¦ˆç»“æœå°è£…ä¸º tool æ¶ˆæ¯åŠ å…¥ä¸Šä¸‹æ–‡
                    self.memory.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": tool_call.function.name,
                        "content": tool_result
                    })

                    # é”™è¯¯å»é‡é€»è¾‘ï¼šæ£€æµ‹è¿”å›å†…å®¹æ˜¯å¦åŒ…å«é”™è¯¯æ ‡è¯†
                    is_error = '"status": "error"' in tool_result or "Error" in tool_result[:50]
                    if is_error:
                        if tool_name in error_tracker and error_tracker[tool_name]["last_error"] == tool_result:
                            error_tracker[tool_name]["count"] += 1
                        else:
                            error_tracker[tool_name] = {"last_error": tool_result, "count": 1}
                    else:
                        # å·¥å…·æˆåŠŸè°ƒç”¨ï¼Œæ¸…é™¤è¯¥å·¥å…·çš„é”™è¯¯è®°å½•
                        error_tracker.pop(tool_name, None)

                # å¦‚æœæ‰€æœ‰è¢«è°ƒç”¨çš„å·¥å…·éƒ½è¢«æ‹¦æˆªäº†ï¼Œæ³¨å…¥å¼ºåˆ¶æ¨ç†æç¤º
                if has_blocked_tool:
                    self.add_message("system",
                        "éƒ¨åˆ†å·¥å…·å› è¿ç»­æŠ¥é”™å·²è¢«è‡ªåŠ¨è·³è¿‡ã€‚"
                        "è¯·åŸºäºç›®å‰å·²è·å–çš„æ‰€æœ‰ä¿¡æ¯ï¼ˆåŒ…æ‹¬å‘Šè­¦å‚æ•°æœ¬èº«ï¼‰ï¼Œç›´æ¥è¿›è¡Œç»¼åˆåˆ†æå¹¶è¾“å‡ºæœ€ç»ˆç»“è®ºã€‚"
                        "ä¸è¦å†å°è¯•è°ƒç”¨å·²å¤±è´¥çš„å·¥å…·ã€‚"
                    )

                turn += 1
                continue
                
            else:
                # 3. å¤§æ¨¡å‹è¾“å‡ºäº†è‡ªç„¶è¯­è¨€çš„ç»“æœï¼ŒReAct å¾ªç¯ç»“æŸ
                print(f"[{self.name}] ğŸ¯ æ€è€ƒå®Œæ¯•ï¼Œå¾—å‡ºæœ€ç»ˆç»“è®ºã€‚")
                return response_message.content
                
        # è¾¾åˆ°æœ€å¤§è½®æ¬¡å¼ºåˆ¶é€€å‡º
        final_msg = f"[{self.name}] âš ï¸ è¾¾åˆ°æœ€å¤§æ€è€ƒè½®æ¬¡ ({max_turns})ï¼Œå¼ºåˆ¶ç»ˆæ­¢æ¨æ¼”ã€‚"
        print(final_msg)
        # æœ€åå†ç»™å¤§æ¨¡å‹ä¸€æ¬¡æœºä¼šè¾“å‡ºç»“è®º
        self.add_message("system", "ä½ å·²ç»è¾¾åˆ°äº†æœ€å¤§å·¥å…·è°ƒç”¨è½®æ¬¡ã€‚è¯·ç«‹å³åŸºäºæ‰€æœ‰å·²è·å–çš„ä¿¡æ¯ï¼Œè¾“å‡ºä½ çš„æœ€ç»ˆåˆ†æç»“è®ºã€‚")
        try:
            final_response = await self.llm_client.chat.completions.create(
                model=self.model_name,
                messages=self.memory
            )
            return final_response.choices[0].message.content
        except Exception:
            return final_msg
