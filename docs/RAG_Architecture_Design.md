# IAI 工业智能体 - RAG 架构设计方案 (企业级双擎架构)

## 1. 背景与目标

当前 IAI 系统已实现基于 Flink 的实时流式计算异常检测，以及基于多智能体（Diagnostic_Expert & Decision_Maker）的全自动诊断与工单下发闭环。

然而，单纯的大模型推理存在“知识盲区”与“幻觉”风险。为了让智能体拥有长期的记忆积累，并且能够精准依据厂家的机器说明书进行故障研判，本项目决定引入 **检索增强生成 (Retrieval-Augmented Generation, RAG)** 技术。

**核心目标：**
- **消除幻觉**：基于真实说明书和历史工单诊断，杜绝大模型凭空捏造不存在的故障部件。
- **构建飞轮**：实现“机器报案 -> 人工结案 -> 经验入库 -> 反哺机器”的自我进化生命周期。
- **解耦设计**：既能处理海量半结构化历史工单，也能解析带复杂图表的几百页 PDF 维修手册。

---

## 2. 核心架构设计：企业级“双擎模式”

鉴于工业场景中存在完全不同的两种知识形态，我们采用**双管齐下的解耦设计**：

### 2.1 引擎一：内网核心动态经验飞轮 (基于 Qdrant)
这是由开发团队自主把控的纯后端、极限轻量级的敏捷知识库，专注于**“动态实战经验”**。

- **核心选型**：`Qdrant` (基于 Rust 的超高性能企业级向量数据库)。
- **部署模式**：作为 Docker 容器直接集成在现有的 `docker-compose.yml` 中。
- **数据源**：系统中经过人工介入并标记为 `COMPLETED`（已结案）的真实维保记录（Ground Truth）。
- **生命周期**：
  1. 工单确认为 `COMPLETED`。
  2. 系统通过 Python 异步任务拦截该事件。
  3. 将“告警参数 + 真因 (Root Cause) + 解决手段”拼接提纯。
  4. 调用嵌入模型（Embedding，如 Ollama `bge-m3`）转化为密集向量，实时存入 Qdrant 的 `experiences_collection`。
- **优势**：极度轻量、毫秒级召回、零数据污染风险（严格的人工闸门）。

### 2.2 引擎二：外挂静态知识中台 (基于 RAGFlow)
这是外挂的重型文档解析与知识问答门户，专注于**“静态本本知识”**。

- **核心选型**：`RAGFlow` (或类似 FastGPT 的具备极强 DeepDoc 深度长文本/表格解析能力的商业级开源系统)。
- **部署模式**：在另外的命名空间或独立机器节点部署完整服务（含自身 UI 和数据库栈）。
- **数据源**：厂家的 PDF 维修手册、SOP 规程、零件保养清单。
- **生命周期**：
  1. 行政或技术专家通过 RAGFlow 可视化 Web 面板，批量上传 PDF。
  2. 平台在后台运用 OCR、版面分析进行极致的 Chunking 和向量化存储。
  3. 平台对外暴露标准化的 RESTful API 搜索引擎接口。
- **优势**：免除开发团队手撕天书 PDF 和复杂表格解析算法的痛苦，开箱即用。不仅赋能大模型，还能让工人直接在网页端当百度搜。

---

## 3. 多智能体工作流集成

我们将在大模型和底层双擎知识库之间，通过 **MCP (Model Context Protocol)** 进行桥接。

### 3.1 改造 MCP Tools
在 `AgentServer/mcp_server.py` 中移除旧的机械查表工具，新增以下能力：

1. **`search_expert_experience` (查过往经验)**：通过本地 Qdrant 客户端，用余弦相似度检索当前报警状态与所有历史“结案工单”的相似度。
2. **`query_manual_knowledge` (查原厂手册)**：通过 HTTP POST 请求调用内网旁路代理的 RAGFlow API，返回 PDF 中的原汁原味权威条款。

### 3.2 诊断专家提示词 (Prompt) 进化
当告警发生时，Diagnostic_Expert 的心智流向如下：
1. `Observation`: 从 Flink 收到设备 PUMP_01 ，温度超限（83°C）。
2. `Action`: 调用 `search_expert_experience` 问：“之前其他 PUMP 设备在这个温度下坏过吗？当时的结案真因是什么？”
3. `Action`: 调用 `query_manual_knowledge` 问：“根据官方手册，PUMP_01 报警温度超 80°C 有哪些强列明的排查步骤？”
4. `Synthesis`: 拿到两方回答后，大模型综合物理分析，出具一份不仅有理有据，而且带有（出处：WO-2025-013，以及《西门子手册页码41》）引用标记的神级《诊断报告》。

---

## 4. 防撞衫与防污染机制 (Data Governance)

工业 RAG 最致命的问题是“模型崩塌”，设计中严格执行以下守则：
- **AI 幻觉隔离**：大模型第一轮猜测出的 PENDING 状态《诊断报告》，绝对不进入任何 Embedding 模型。向量库只会吃下由拥有特权的人工维修账号修改确认过的闭环数据。

## 5. 落地规划蓝图

- **Phase 1**：在 docker-compose 搭建 Qdrant，并编写 Python 脚本清洗旧的假数据，打通动态工单飞轮（MVP重点）。
- **Phase 2**：在 AgentServer 引入本地化开源 BGE 嵌入模型。大模型在诊断时开始带有记忆。
- **Phase 3**：另起炉灶架设 RAGFlow 环境，MCP 工具对接 RAGFlow 外部 API 面向生产落地。
