package com.iai.flink;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.node.ObjectNode;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.connector.sink2.Sink;
import org.apache.flink.api.connector.sink2.SinkWriter;
import org.apache.flink.api.connector.sink2.WriterInitContext;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.connector.kafka.source.KafkaSource;
import org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.windowing.ProcessWindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.SlidingProcessingTimeWindows;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.Collector;
import org.apache.http.client.methods.HttpPost;
import org.apache.http.entity.StringEntity;
import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.impl.client.HttpClients;

import java.io.IOException;
import java.io.Serializable;
import java.time.Duration;

/**
 * å®æ—¶å¼‚å¸¸æ£€æµ‹ Flink ä»»åŠ¡ï¼ˆå…¼å®¹ Flink 2.xï¼‰
 * ä¸å†ä¾èµ–é¢„è®¾çš„ status æ ‡ç­¾ï¼Œè€Œæ˜¯ä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—è¿‘ 10 ç§’çš„åŠ¨æ€å‡å€¼ã€‚
 * å¦‚æœæ¸©åº¦æˆ–éœ‡åŠ¨å‡å€¼è¶…è¿‡åŠ¨æ€é˜ˆå€¼ï¼Œåˆ™ä¸»åŠ¨åˆ¤å®šä¸º ANOMALYï¼Œå¹¶å›è°ƒ AgentServerã€‚
 */
public class AnomalyDetectionJob {

    public static void main(String[] args) throws Exception {
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        KafkaSource<String> source = KafkaSource.<String>builder()
                .setBootstrapServers("192.168.0.105:9092")
                .setTopics("raw_sensor_data")
                .setGroupId("flink-iai-anomaly-group")
                .setStartingOffsets(OffsetsInitializer.latest())
                .setValueOnlyDeserializer(new SimpleStringSchema())
                .build();

        DataStream<String> stream = env.fromSource(source, WatermarkStrategy.noWatermarks(), "Kafka Source");

        // 1. è§£æ JSON å¹¶æå– Tuple2<è®¾å¤‡ID, JsonNode>
        DataStream<Tuple2<String, JsonNode>> parsedStream = stream
                .map(new MapFunction<String, Tuple2<String, JsonNode>>() {
                    private final ObjectMapper mapper = new ObjectMapper();

                    @Override
                    public Tuple2<String, JsonNode> map(String value) throws Exception {
                        JsonNode node = mapper.readTree(value);
                        return new Tuple2<>(node.get("device_id").asText(), node);
                    }
                }).returns(Types.TUPLE(Types.STRING, Types.GENERIC(JsonNode.class)));

        // 2. æ ¸å¿ƒï¼šè®¾å®š 10ç§’çª—å£ï¼Œæ­¥é•¿ 2ç§’ çš„æ»‘åŠ¨çª—å£è¿›è¡Œå‡å€¼ä¸çªå˜æ£€æµ‹
        DataStream<String> anomalyStream = parsedStream
                .keyBy(t -> t.f0)
                .window(SlidingProcessingTimeWindows.of(Duration.ofSeconds(10), Duration.ofSeconds(2)))
                .process(new AnomalyEvaluator());

        // 3. å°†æ£€æµ‹å‡ºçš„çœŸå®å¼‚å¸¸å‘é€åˆ° Webhook
        anomalyStream.sinkTo(new HttpWebhookSink());

        System.out.println("âš¡ Flink æ™ºèƒ½æ»‘çª—å¼‚å¸¸æ£€æµ‹ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨ç›‘å¬ Kafka: raw_sensor_data...");
        env.execute("IIoT Advanced Anomaly Detection Job");
    }

    /**
     * æ»‘åŠ¨çª—å£å¤„ç†é€»è¾‘ï¼šåœ¨çª—å£å†…è®¡ç®—å‡å€¼ï¼Œåˆ¤æ–­æ˜¯å¦çœŸå®è¶…æ ‡
     */
    public static class AnomalyEvaluator
            extends ProcessWindowFunction<Tuple2<String, JsonNode>, String, String, TimeWindow> {
        private static final ObjectMapper mapper = new ObjectMapper();

        // è®¾å®šçš„å·¥ä¸šé¢„è­¦é˜ˆå€¼
        private static final double TEMP_THRESHOLD = 65.0;
        private static final double VIB_THRESHOLD = 1.2;

        @Override
        public void process(String deviceId, Context context, Iterable<Tuple2<String, JsonNode>> elements,
                Collector<String> out) throws Exception {
            double sumTemp = 0.0;
            double sumVib = 0.0;
            int count = 0;

            JsonNode lastNode = null;

            for (Tuple2<String, JsonNode> element : elements) {
                sumTemp += element.f1.get("temperature").asDouble();
                sumVib += element.f1.get("vibration").asDouble();
                count++;
                lastNode = element.f1;
            }

            if (count > 0) {
                double avgTemp = sumTemp / count;
                double avgVib = sumVib / count;

                // å¦‚æœè®¡ç®—å‡ºçš„å¹³å‡å€¼è¶…æ ‡ï¼Œåˆ™åˆ¤å®šä¸ºçœŸå®å¼‚å¸¸
                if (avgTemp > TEMP_THRESHOLD || avgVib > VIB_THRESHOLD) {
                    ObjectNode alertPayload = mapper.createObjectNode();
                    alertPayload.put("device_id", deviceId);
                    alertPayload.put("status", "ANOMALY");
                    alertPayload.put("temperature", Math.round(avgTemp * 100.0) / 100.0);
                    alertPayload.put("vibration", Math.round(avgVib * 1000.0) / 1000.0);

                    if (lastNode != null && lastNode.has("timestamp")) {
                        alertPayload.put("timestamp", lastNode.get("timestamp").asText());
                    } else {
                        alertPayload.put("timestamp", java.time.Instant.now().toString());
                    }

                    alertPayload.put("trigger_reason", avgTemp > TEMP_THRESHOLD
                            ? "10ç§’å¹³å‡æ¸©åº¦çªå˜ (" + alertPayload.get("temperature").asDouble() + " > " + TEMP_THRESHOLD + ")"
                            : "10ç§’å¹³å‡éœ‡åŠ¨è¶…æ ‡ (" + alertPayload.get("vibration").asDouble() + " > " + VIB_THRESHOLD + ")");

                    out.collect(alertPayload.toString());
                }
            }
        }
    }

    public static class HttpWebhookSink implements Sink<String>, Serializable {
        private static final long serialVersionUID = 1L;

        @Override
        public SinkWriter<String> createWriter(WriterInitContext context) throws IOException {
            return new HttpWebhookWriter();
        }

        private static class HttpWebhookWriter implements SinkWriter<String> {
            private final String webhookUrl = System.getenv().getOrDefault(
                    "AGENT_SERVER_URL",
                    "http://172.18.0.1:8000/api/v1/alerts");

            @Override
            public void write(String element, Context context) throws IOException, InterruptedException {
                System.out.println("ğŸš¨ Flink [æ»‘çª—ç®—æ³•æ•è·å¼‚å¸¸] -> æ­£åœ¨è¯·æ±‚ AgentServer: " + element);
                try (CloseableHttpClient httpClient = HttpClients.createDefault()) {
                    HttpPost httpPost = new HttpPost(webhookUrl);
                    StringEntity entity = new StringEntity(element, "UTF-8");
                    httpPost.setEntity(entity);
                    httpPost.setHeader("Content-type", "application/json");
                    httpClient.execute(httpPost);
                    System.out.println("âœ… å·²ä¸‹å‘æ™ºèƒ½è¯Šæ–­ä»»åŠ¡ã€‚");
                } catch (Exception e) {
                    System.err.println("âŒ è°ƒç”¨ AgentServer å¤±è´¥: " + e.getMessage());
                }
            }

            @Override
            public void flush(boolean endOfInput) throws IOException, InterruptedException {
            }

            @Override
            public void close() throws Exception {
            }
        }
    }
}
